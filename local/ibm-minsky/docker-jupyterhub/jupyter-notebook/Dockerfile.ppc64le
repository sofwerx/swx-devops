FROM nvidia/cuda-ppc64le:9.0-cudnn7-devel-ubuntu16.04

# This is a mess. It is a cobbled together patchwork of the upstream Dockerfiles from JupyterHub, with a smattering of IBM Power8 architecture build magic

USER root

ENV DEBIAN_FRONTEND noninteractive

# Install the IBM xl-compiler
RUN apt-get update
RUN apt-get install -y wget
RUN wget -q http://public.dhe.ibm.com/software/server/POWER/Linux/xl-compiler/eval/ppc64le/ubuntu/public.gpg -O- | apt-key add - && \
    echo "deb http://public.dhe.ibm.com/software/server/POWER/Linux/xl-compiler/eval/ppc64le/ubuntu/ trusty main" | tee /etc/apt/sources.list.d/ibm-xl-compiler-eval.list && \
    apt-get update && \
    apt-get install -y libxlmass-devel.9.1.0 libxlc-devel libxlf-devel libxlsmp-devel.5.1.0 xlc.16.1.0 xlc-license-community.16.1.0 xlf.16.1.0 xlf-license-community.16.1.0

# Install the advance-toolchain (at) compiler
#RUN echo "deb http://ports.ubuntu.com/ubuntu-ports xenial main security universe multiverse" > /etc/apt/sources.list.d/ports.list
#RUN echo "deb http://us.ports.ubuntu.com/ubuntu-ports/ xenial-backports main restricted universe multiverse" > /etc/apt/sources.list.d/backports.list
#RUN apt-get update
#RUN apt-get install -y openssl wget zlib1g-dev
#RUN echo "deb ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/ubuntu xenial at10.0" > /etc/apt/sources.list.d/at10.list
#RUN wget -O - ftp://ftp.unicamp.br/pub/linuxpatch/toolchain/at/ubuntu/dists/xenial/6976a827.gpg.key | apt-key add -
#RUN apt-get update
#RUN apt-get install -y advance-toolchain-at10.0-runtime \
#        advance-toolchain-at10.0-devel \
#        advance-toolchain-at10.0-perf \
#        advance-toolchain-at10.0-mcore-libs

ENV LD_LIBRARY_PATH=/usr/lib/powerpc64le-linux-gnu/

ENV PATH=/opt/at10.0/bin:$PATH

# Install all OS dependencies for notebook server that starts but lacks all
# features (e.g., download as all possible file formats)
RUN apt-get update && apt-get -yq dist-upgrade \
 && apt-get install -yq --no-install-recommends \
    build-essential \
    bzip2 \
    ca-certificates \
    cmake \
    git \
    locales \
    sudo \
    wget \
    curl \
    && apt-get clean && \
    rm -rf /var/lib/apt/lists/*

RUN echo "LANGUAGE=en_US.UTF-8" >> /etc/default/locale \
 && echo "LC_ALL=en_US.UTF-8" >> /etc/default/locale \
 && echo "LC_TYPE=en_US.UTF-8" >> /etc/default/locale \
 && locale-gen en_US en_US.UTF-8

#build and install Tini for ppc64le
RUN wget https://github.com/krallin/tini/archive/v0.18.0.tar.gz && \
    tar zxvf v0.18.0.tar.gz && \
    rm -rf v0.18.0.tar.gz
WORKDIR tini-0.18.0/
RUN cmake . && make install
RUN mv ./tini /usr/local/bin/tini  && \
    chmod +x /usr/local/bin/tini
WORKDIR ..

# Configure environment
ENV CONDA_DIR=/opt/conda \
    SHELL=/bin/bash \
    NB_USER=jovyan \
    NB_UID=1000 \
    NB_GID=100 \
    LC_ALL=en_US.UTF-8 \
    LANG=en_US.UTF-8 \
    LANGUAGE=en_US.UTF-8
ENV PATH=$CONDA_DIR/bin:$PATH \
    HOME=/home/$NB_USER

ADD fix-permissions /usr/local/bin/fix-permissions
# Create jovyan user with UID=1000 and in the 'users' group
RUN groupadd wheel -g 11 && \
    echo "auth required pam_wheel.so use_uid" >> /etc/pam.d/su && \
    useradd -m -s /bin/bash -N -u $NB_UID $NB_USER && \
    mkdir -p $CONDA_DIR && \
    chown $NB_USER:$NB_GID $CONDA_DIR && \
    chmod g+w /etc/passwd && \
    fix-permissions $HOME && \
    fix-permissions $CONDA_DIR

USER $NB_UID

# Setup jovyan home directory
RUN mkdir /home/$NB_USER/work && \
    mkdir /home/$NB_USER/.jupyter && \
    echo "cacert=/etc/ssl/certs/ca-certificates.crt" > /home/$NB_USER/.curlrc  && \
    fix-permissions /home/$NB_USER

# Install conda as jovyan
ENV MINICONDA_VERSION 4.5.4
RUN cd /tmp && \
    wget --quiet https://repo.continuum.io/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-ppc64le.sh && \
    echo "05c1e073f262105179cf57920dfc4d43 *Miniconda3-${MINICONDA_VERSION}-Linux-ppc64le.sh" | md5sum -c - && \
    /bin/bash Miniconda3-${MINICONDA_VERSION}-Linux-ppc64le.sh -f -b -p $CONDA_DIR && \
    rm Miniconda3-${MINICONDA_VERSION}-Linux-ppc64le.sh && \
    $CONDA_DIR/bin/conda config --system --prepend channels conda-forge && \
    $CONDA_DIR/bin/conda config --system --set auto_update_conda false && \
    $CONDA_DIR/bin/conda config --system --set show_channel_urls true && \
    $CONDA_DIR/bin/conda install --quiet --yes conda="${MINICONDA_VERSION%.*}.*" && \
    $CONDA_DIR/bin/conda update --all --quiet --yes && \
    conda clean -tipsy && \
    rm -rf /home/$NB_USER/.cache/yarn && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

# Install Jupyter Notebook, Lab, and Hub
# Generate a notebook server config
# Cleanup temporary files
# Correct permissions
# Do all this in a single RUN command to avoid duplicating all of the
# files across image layers when the permissions change
RUN yes | pip install --upgrade pip
RUN yes | pip install --quiet --no-cache-dir \
    'jupyterhub==0.9.*'
RUN $CONDA_DIR/bin/conda install -c anaconda jupyterlab && \
    $CONDA_DIR/bin/conda install -c anaconda notebook

USER root

# gpg keys listed at https://github.com/nodejs/node#release-team
RUN set -ex \
  && for key in \
    94AE36675C464D64BAFA68DD7434390BDBE9B9C5 \
    FD3A5288F042B6850C66B31F09FE44734EB7990E \
    71DCFD284A79C3B38668286BC97EC7A07EDE3FC1 \
    DD8F2338BAE7501E3DD5AC78C273792F7D83545D \
    C4F0DFFF4E8C1A8236409D08E73BC641CC11F4C8 \
    B9AE9905FFD7803F25714661B63B535A4C206CA9 \
    56730D5401028683275BD23C23EFEFE93C4CFFFE \
    77984A986EBC2AA786BC0F66B01FBB92821C587A \
    8FCCA13FEF1D0C2E91008E09770F7A9A5AE15600 \
  ; do \
    gpg --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys "$key" || \
    gpg --keyserver hkp://ipv4.pool.sks-keyservers.net --recv-keys "$key" || \
    gpg --keyserver hkp://pgp.mit.edu:80 --recv-keys "$key" ; \
  done

ENV NODE_VERSION 10.9.0

RUN ARCH= && dpkgArch="$(dpkg --print-architecture)" \
  && case "${dpkgArch##*-}" in \
    amd64) ARCH='x64';; \
    ppc64el) ARCH='ppc64le';; \
    s390x) ARCH='s390x';; \
    arm64) ARCH='arm64';; \
    armhf) ARCH='armv7l';; \
    i386) ARCH='x86';; \
    *) echo "unsupported architecture"; exit 1 ;; \
  esac \
  && curl -fsSLO --compressed "https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-$ARCH.tar.xz" \
  && curl -fsSLO --compressed "https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc" \
  && gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \
  && grep " node-v$NODE_VERSION-linux-$ARCH.tar.xz\$" SHASUMS256.txt | sha256sum -c - \
  && tar -xJf "node-v$NODE_VERSION-linux-$ARCH.tar.xz" -C /usr/local --strip-components=1 --no-same-owner \
  && rm "node-v$NODE_VERSION-linux-$ARCH.tar.xz" SHASUMS256.txt.asc SHASUMS256.txt \
  && ln -s /usr/local/bin/node /usr/local/bin/nodejs

ENV YARN_VERSION 1.9.2

RUN set -ex \
  && for key in \
    6A010C5166006599AA17F08146C2130DFD2497F5 \
  ; do \
    gpg --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys "$key" || \
    gpg --keyserver hkp://ipv4.pool.sks-keyservers.net --recv-keys "$key" || \
    gpg --keyserver hkp://pgp.mit.edu:80 --recv-keys "$key" ; \
  done \
  && curl -fsSLO --compressed "https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz" \
  && curl -fsSLO --compressed "https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz.asc" \
  && gpg --batch --verify yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \
  && mkdir -p /opt \
  && tar -xzf yarn-v$YARN_VERSION.tar.gz -C /opt/ \
  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarn /usr/local/bin/yarn \
  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarnpkg /usr/local/bin/yarnpkg \
  && rm yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz

USER $NB_UID

RUN jupyter labextension install @jupyterlab/hub-extension@^0.11.0 && \
    npm cache clean --force && \
    jupyter notebook --generate-config && \
    rm -rf $CONDA_DIR/share/jupyter/lab/staging && \
    rm -rf /home/$NB_USER/.cache/yarn

USER root

RUN fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

EXPOSE 8888
WORKDIR /home/$NB_USER/work
RUN echo "ALL            ALL = (ALL) NOPASSWD: ALL" >> /etc/sudoers

# Configure container startup
ENTRYPOINT ["tini", "-g", "--"]
CMD ["start-notebook.sh"]

# Add local files as late as possible to avoid cache busting
COPY start.sh /usr/local/bin/
COPY start-notebook.sh /usr/local/bin/
COPY start-singleuser.sh /usr/local/bin/
COPY jupyter_notebook_config.py /home/$NB_USER/.jupyter/
RUN chown -R $NB_USER:users /home/$NB_USER/.jupyter

# Switch back to jovyan to avoid accidental container runs as root
USER $NB_UID

# Install minimal notebook (jupyter/minimal-notebook)

USER root

# Install all OS dependencies for fully functional notebook server
RUN apt-get update && apt-get install -yq --no-install-recommends \
    build-essential \
    emacs \
    git \
    inkscape \
    jed \
    libsm6 \
    libxext-dev \
    libxrender1 \
    lmodern \
    netcat \
    pandoc \
    python-dev \
    texlive-fonts-extra \
    texlive-fonts-recommended \
    texlive-generic-recommended \
    texlive-latex-base \
    texlive-latex-extra \
    texlive-xetex \
    unzip \
    nano \
    && apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install scipy (jupyter/scipy-notebook)
USER root

# ffmpeg for matplotlib anim
RUN apt-get update && \
    apt-get install -y --no-install-recommends ffmpeg && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

USER $NB_UID

# Install Python 3 packages
# Remove pyqt and qt pulled in for matplotlib since we're only ever going to
# use notebook-friendly backends in these images
##    'matplotlib=2.2*' \
##    conda remove --quiet --yes --force qt pyqt && \
RUN conda install --quiet --yes \
    'ipywidgets=7.2*' \
    'numexpr=2.6*' \
    'seaborn=0.9*' \
    'scikit-learn=0.19*' \
    'scikit-image=0.14*' \
    'sympy=1.1*' \
    'cython=0.28*' \
    'patsy=0.5*' \
    'statsmodels=0.9*' \
    'cloudpickle=0.5*' \
    'dill=0.2*' \
    'bokeh=0.12*' \
    'sqlalchemy=1.2*' \
    'hdf5=1.10*' \
    'h5py=2.7*' \
    'vincent=0.4.*' \
    'beautifulsoup4=4.6.*' \
    'protobuf=3.*' \
    'xlrd'  && \
    conda clean -tipsy && \
    # Activate ipywidgets extension in the environment that runs the notebook server
    jupyter nbextension enable --py widgetsnbextension --sys-prefix && \
    # Also activate ipywidgets extension for JupyterLab
    jupyter labextension install @jupyter-widgets/jupyterlab-manager@^0.37.0 && \
    jupyter labextension install jupyterlab_bokeh@^0.6.0 && \
    npm cache clean --force && \
    rm -rf $CONDA_DIR/share/jupyter/lab/staging && \
    rm -rf /home/$NB_USER/.cache/yarn && \
    rm -rf /home/$NB_USER/.node-gyp && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

# numba needs this
RUN conda install --channel=numba llvmlite

USER root

ENV CFLAGS="-L/opt/ibm/xlmass/9.1.0/lib -L/opt/ibm/xlf/16.1.0 -L/opt/ibm/xlC/16.1.0/lib -L/opt/ibm/lib/ -L/opt/ibm/xlsmp/5.1.0/lib"
RUN for dir in $(find /opt/ibm -name lib) ; do echo $dir >> /etc/ld.so.conf.d/xl.conf ;  done ; ldconfig -v

RUN git clone git://github.com/xianyi/OpenBLAS.git && \
    cd OpenBLAS && \
    make USE_MASS=1 TARGET=POWER8 && \
    make install && \
    cd .. && \
    rm -fr OpenBLAS

USER $NB_UID

#RUN yes | pip install --quiet --no-cache-dir \
#    'blas'
#    'conda-forge::blas=*=openblas' \
#    'numba=0.38*' \

RUN git clone https://github.com/numba/numba.git && \
   cd numba && \
   git checkout 0.38.1 && \
   pip install -r requirements.txt && \
   python setup.py build_ext --inplace && \
   python setup.py install && \
   cd .. && \
   rm -fr numba

USER root

# Install facets which does not have a pip or conda package at the moment
RUN cd /tmp && \
    git clone https://github.com/PAIR-code/facets.git && \
    cd facets && \
    jupyter nbextension install facets-dist/ --sys-prefix && \
    cd && \
    rm -rf /tmp/facets && \
    fix-permissions $CONDA_DIR && \
    fix-permissions /home/$NB_USER

# Import matplotlib the first time to build the font cache.
ENV XDG_CACHE_HOME /home/$NB_USER/.cache/
RUN MPLBACKEND=Agg python -c "import matplotlib.pyplot" && \
    fix-permissions /home/$NB_USER

# prepare some nvidia things
RUN echo /usr/local/cuda-9.0/extras/CUPTI/lib64 > /etc/ld.so.conf.d/cupti.conf && ldconfig -v

# nccl v1 uses cuda8-toolkit, and we're using cuda9, so we can't use it
#RUN conda install -c anaconda nccl
# There is no nccl v2 for ppc64le, and no source to build it

# Install Tensorflow (jupyter/tensorflow-notebook)
# http://ftp.unicamp.br/pub/ppc64el/ai_frameworks/tensorflow/
# http://ftp.unicamp.br/pub/ppc64el/ai_frameworks/tensorflow/tensorflow-1.10.0-cp27-none-linux_ppc64le.whl
# http://ftp.unicamp.br/pub/ppc64el/ai_frameworks/tensorflow/tensorflow-1.9.0-cp27-none-linux_ppc64le.whl
# http://ftp.unicamp.br/pub/ppc64el/ai_frameworks/tensorflow/tensorflow-1.8.0-cp27-none-linux_ppc64le.whl
USER root

# In the Ubuntu 16.04 images, cudnn is placed in system paths. Move them to
# /usr/local/cuda
RUN cp -P /usr/include/cudnn.h /usr/local/cuda/include
RUN cp -P /usr/lib/powerpc64le-linux-gnu/libcudnn* /usr/local/cuda/lib64

# Configure the build for our CUDA configuration.
ENV TF_NEED_CUDA 1
ENV TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.5,5.2,6.0,6.1

# TODO get NCCL 2 in the docker image
ENV TF_NCCL_VERSION 1

RUN git clone https://github.com/tensorflow/tensorflow && \
    cd tensorflow && \
    git checkout v1.10.0 && \
    ./tensorflow/tools/ci_build/install/install_bootstrap_deb_packages.sh && \
    add-apt-repository -y ppa:openjdk-r/ppa && \
    ./tensorflow/tools/ci_build/install/install_deb_packages.sh && \
    ./tensorflow/tools/ci_build/install/install_hdf5_ppc64le.sh && \
    apt-get install -y gfortran && \
    ./tensorflow/tools/ci_build/install/install_python3.6_pip_packages.sh && \
    ./tensorflow/tools/ci_build/install/install_bazel_from_source.sh && \
    ./tensorflow/tools/ci_build/install/install_golang_ppc64le.sh && \
    cp ./tensorflow/tools/ci_build/install/.bazelrc /etc/bazel.bazelrc && \
    ./tensorflow/tools/ci_build/builds/configured GPU && \
    ln -s /usr/local/cuda-9.0/targets/ppc64le-linux/lib/stubs/libcuda.so /usr/local/cuda-9.0/targets/ppc64le-linux/lib/stubs/libcuda.so.1 && \
    echo /usr/local/cuda-9.0/targets/ppc64le-linux/lib/stubs > /etc/ld.so.conf.d/cuda-9.0.conf && ldconfig && \
    bazel build -j `nproc` --ram_utilization_factor 50 -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package && \
    ./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp && \
    pip install /tmp/tensorflow-1.10.0-cp36-cp36m-linux_ppc64le.whl && \
    rm -f /tmp/tensorflow-1.10.0-cp36-cp36m-linux_ppc64le.whl && \
    rm -f /etc/ld.so.conf.d/cuda-9.0.conf && ldconfig && \
    echo /usr/local/nvidia/lib64 > /etc/ld.so.conf.d/nvidia-lib64.conf && ldconfig && \
    cd .. && \
    rm -fr tensorflow

RUN git clone https://github.com/keras-team/keras.git keras/ && \
    cd keras && \
    git checkout 2.2.2 && \
    python setup.py install && \
    cd .. && \
    rm -fr keras

RUN yes | pip install pyspark

# Install R, re-built from upstream ubuntu xenial source packages.
RUN echo "deb http://cran.rstudio.com/bin/linux/ubuntu xenial/" | tee -a /etc/apt/sources.list.d/r-base.list && \
    echo "deb-src http://cran.rstudio.com/bin/linux/ubuntu xenial/" | tee -a /etc/apt/sources.list.d/r-base.list && \
    apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 && \
    apt-get update

RUN apt-get build-dep -y r-base && \
    mkdir r && \
    cd r && \
    apt-get source r-base

RUN cd r/r-base-3.4.4 ; dpkg-buildpackage || true
#  rm -fr r-base-3.4.4 && \

RUN dpkg -i r/*.deb || true
RUN apt-get -f -y install && \
    dpkg -i r/*.deb && \
    rm -fr r

# Install Jupyter IRkernel for the R kernel
RUN R --vanilla -e "install.packages('devtools', repos='http://cran.us.r-project.org')"
RUN R --vanilla -e "devtools::install_github('IRkernel/IRkernel')"
RUN R --vanilla -e "IRkernel::installspec()"

# Install gpuR
#RUN R --vanilla -e "install.packages('gpuR', repos='http://cran.us.r-project.org')"

#RUN yes | conda install conda-build
##RUN pip install --upgrade --force-reinstall scikit-image
#RUN pip install --upgrade --force-reinstall scipy
#RUN apt-get install -y vim pico

#RUN git clone git://github.com/moble/jupyter_boilerplate && \
#    jupyter nbextension install jupyter_boilerplate && \
#    jupyter nbextension enable jupyter_boilerplate/main

# Install the python2 kernel and conda py2 environment
RUN conda create -n py2 python=2 anaconda
RUN chmod 755 /opt/conda/bin/activate
RUN apt-get install -y libzmq-dev
RUN bash -c 'source activate py2 ; \
    python2 -m pip install ipykernel && \
    python2 -m ipykernel install --user'

# Install Octave kernel (MATLAB like syntax)
RUN apt-get install -y octave
RUN pip install octave_kernel

# Install Scilab kernel
RUN apt-get install -y scilab
RUN pip install scilab_kernel

ADD test_cuda_docker.ipynb .

RUN pip install -U numpy==1.14.5
RUN pip install -U scipy
RUN pip install -U scikit-image

RUN chown -R $NB_USER:users /home/$NB_USER
RUN chown -R $NB_USER:users /usr/local

## Install VNC
#RUN apt-get install -y --no-install-recommends xterm xfonts-base x11-xserver-utils supervisor openbox wget bzip2 ca-certificates websockify xinit novnc xfce4
#
#RUN pip install nbnovnc
#
#RUN jupyter serverextension enable  --py nbserverproxy
#RUN jupyter serverextension enable  --py nbnovnc
#RUN jupyter nbextension     install --py nbnovnc
#RUN jupyter nbextension     enable  --py nbnovnc
#
#RUN git clone https://github.com/ryanlovett/nbnovnc nbnovnc && \
#    cd nbnovnc && \
#    python setup.py install && \
#    cd .. && \
#    rm -fr nbnovnc
#
#RUN git clone https://github.com/jupyterhub/nbserverproxy nbserverproxy && \
#    cd nbserverproxy && \
#    python setup.py install && \
#    cd .. && \
#    rm -fr nbserverproxy
#
#RUN git clone https://github.com/novnc/websockify websockify && \
#    cd websockify && \
#    python setup.py install && \
#    cd .. && \
#    rm -fr websockify
#
#RUN jupyter serverextension enable  --py nbserverproxy
#RUN jupyter serverextension enable  --py nbnovnc

## This is not necessary
#COPY supervisord.conf /etc/supervisor/supervisord.conf
#COPY menu.xml /etc/xdg/openbox/menu.xml
#
#CMD "/usr/bin/supervisord"

